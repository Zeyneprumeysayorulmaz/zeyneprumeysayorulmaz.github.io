---
title: Kubernetes NotlarÄ±m VII- Resource Limits
---

> Merhabalar Kubernetes yazÄ± serisine hÄ±z kesmeden devam ediyorum. Bu yazÄ±mda resource limits ve environment variable konularÄ±na deÄŸineceÄŸim. Keyifli okumalar..

## Resource Limits
Containerlar aksi belirtilmedikÃ§e varsayÄ±lan olarak Ã¼stÃ¼nde Ã§alÄ±ÅŸtÄ±klarÄ± hostun cpu ve memory kaynaklarÄ±na sÄ±nÄ±rsÄ±z ÅŸekilde eriÅŸebilirler. Bu durumda Ã¶zellikle kubernetes gibi yÃ¼zlerce containerlarÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± daÄŸÄ±tÄ±k yapÄ±larda bir sorun oluÅŸturur.
EÄŸer bir pod Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ± hostun tÃ¼m kaynaklarÄ±nÄ± tÃ¼ketiyorsa aynÄ± host Ã¼zerinde Ã§alÄ±ÅŸan diÄŸer podlar iÃ§in sÄ±kÄ±ntÄ±lÄ± bir durum teÅŸkil eder, diÄŸer podlar iÅŸlerini dÃ¼zgÃ¼n yapamaz hale gelir. Bu nedenle podlarÄ±n iÃ§inde Ã§alÄ±ÅŸan containerlar iÃ§in cpu ve memory limitlerini kÄ±sÄ±tlamamÄ±z gerekir. Pod tanÄ±mlarÄ±nda kullanÄ±lan request ve limit anahtarlarÄ± bizlere bu imkanÄ± verir.  

* **CPU**

Kubernetes Ã¼zerinde cpu kÄ±sÄ±tlamalarÄ±;

Her worker node'un belirli cpu kaynaklarÄ± mevcuttur. Bu kaynaklar cloud Ã¼stÃ¼nde ya da sanal olarak Ã§alÄ±ÅŸan sistemlerde **vCPU** olarak, baremetal sunucularda ise **hyperthread** olarak hesaplanÄ±r. 

Ã–rneÄŸin aÅŸaÄŸÄ±daki gibi bir tanÄ±mda, bu podun Ã§alÄ±ÅŸtÄ±ÄŸÄ± node Ã¼zerindeki corelardan sadece 1 tanesini kullanabileceÄŸi anlamÄ±na gelir.
![]({{ 'assets/img/resourcecpu.PNG' | relative_url }})

Cpu tanÄ±mlarÄ±nda kesirli deÄŸerler kullanabiliriz. 0,5 CPU talep eden bir container, 1CPU talep eden bir container'Ä±n yarÄ±sÄ± kadar cpu alÄ±r demektir. Mili anlamÄ±nda m son eki kullanÄ±labilir. 1m'den daha ince hassasiyetin tanÄ±mlanmasÄ±na izin verilmez.

CPU her zaman mutlak bir miktar olarak talep edilir,  gÃ¶reli bir miktar olarak talep edilmez; 0,1 tek Ã§ekirdekli, Ã§ift Ã§ekirdekli veya 48 Ã§ekirdekli bir makinede de aynÄ± miktarda CPU'dur.

1 CPU Core = cpu: "1" = cpu: "1000" = cpu: "1000m"

1 CPU Core!un %10'u = cpu: "0,1" = cpu: "100" = cpu: "100m"

* **Memory**

Kubernetes Ã¼zerinde memory kÄ±sÄ±tlamalarÄ±;

ContainerlarÄ±n kullanacaÄŸÄ± max memory miktarÄ±nÄ± byte cinsinden tanÄ±mlayabilirsiniz.  Clusterda mevcut durumda kullanÄ±labilir bellek varsa, bir container belirlenen bellek isteÄŸini aÅŸabilir. Ancak bir container bellek sÄ±nÄ±rÄ±ndan fazlasÄ±nÄ± kullanmasÄ±na izin verilmez. Container limitlerin Ã¼stÃ¼nde bellek tÃ¼ketmeye  devam ederse, container sonlandÄ±rÄ±lÄ±r ve kubelet onu yeniden baÅŸlatÄ±r.

![]({{ 'assets/img/resourcelimits.PNG' | relative_url }})

**Requests altÄ±nda tanÄ±mladÄ±ÄŸÄ±mÄ±z deÄŸerler;**

Kubernetes bu podu oluÅŸturmaya baÅŸladÄ±ÄŸÄ± zaman scheduler bu podun oluÅŸturulacaÄŸÄ± bir node seÃ§ecektir. Bu seÃ§me aÅŸamasÄ±nda kubernetes'e diyoruz ki bu podu en az  request altÄ±nda verdiÄŸim deÄŸerler kadar kaynak olan bir node Ã¼zerinde schedule et. KÄ±sacasÄ± bu podun oluÅŸturulabilmesi iÃ§in minimum ne kadar boÅŸ kaynaÄŸÄ±n olmasÄ± gerektiÄŸini belirtiyoruz.

**Limits altÄ±nda tanÄ±mladÄ±ÄŸÄ±mÄ±z deÄŸerler ise;**

Bu container'Ä±n en fazla kullanabileceÄŸi sistem kaynaÄŸÄ±nÄ± belirtir. EÄŸer container limit altÄ±nda verilen  cpu deÄŸerinden fazlasÄ±na eriÅŸmeye Ã§alÄ±ÅŸÄ±rsa mÃ¼mkÃ¼n olmayacaktÄ±r yani eriÅŸemeyecektir.

Fakat memory limitinde durum biraz farklÄ±dÄ±r, memory allocation CPU gibi Ã§alÄ±ÅŸmaz. Container limit altÄ±nda verilen memory deÄŸerinden daha fazlasÄ±nÄ± sistemden talep edebilir ve sistem bunu varsayÄ±lan olarak engelleme ÅŸansÄ±na sahip deÄŸildir. Container limit memory deÄŸerine geldiÄŸinde ve daha fazlasÄ±nÄ± allocate edebileceÄŸi bir mekanizma olmadÄ±ÄŸÄ±ndan bu duruma gelindiÄŸinde pod "**OOMKilled"** yani **"Out of Memory Killed"** durumuna geÃ§erek restart edilir. Bu nedenle eÄŸer limit altÄ±nda verilen memoryden fazlasÄ± container tarafÄ±ndan talep edilirse pod restart edilecektir. TÃ¼m bunlar dÃ¼ÅŸÃ¼nÃ¼ldÃ¼ÄŸÃ¼nde limit kÄ±sÄ±tlarÄ± uygulamanÄ±n davranÄ±ÅŸÄ±na uygun olarak belirlenmelidir. 

![]({{ 'assets/img/oomkilled.gif' | relative_url }})


## Environment Variables
Ã–rneÄŸin bir web uygulamamÄ±z var ve bu web uygulamasÄ± bir db'ye baÄŸlanarak verilerini burada saklÄ±yor olsun. Bu uygulamanÄ±n baÄŸlandÄ±ÄŸÄ± veritabanÄ± sunucu adresi ve kullanÄ±cÄ± bilgileri gibi bilgileri uygulama iÃ§ine hard-coded olarak gÃ¶mdÃ¼k diyelim. Daha sonra bu uygulamayÄ± container imajÄ± haline getirdik. Bu senaryoda bir kaÃ§ sÄ±kÄ±ntÄ±lÄ± durum var. VeritabanÄ± baÄŸlantÄ± bilgilerini container imajÄ± iÃ§erisinde hard-coded olarak yazdÄ±k, bu gÃ¼venlik anlamÄ±nda best practice deÄŸildir.  Bir diÄŸer sÄ±kÄ±ntÄ± da bu imajdan container oluÅŸturmak istediÄŸim zaman bu container her defasÄ±nda aynÄ± veritabanÄ±na aynÄ± user ve ÅŸifre ile baÄŸlanacak, bu senaryoda veritabanÄ± adresim test ve prod ortamlarda ayrÄ± olabilir veya bu user ve ÅŸifre bilgilerini zaman iÃ§ersinde gÃ¼ncellemiÅŸ olabiliriz.

Ä°ÅŸte bu tarz ortama gÃ¶re deÄŸiÅŸebilen veya hassas bilgileri container iÃ§erisine gÃ¶mmek saÄŸlÄ±klÄ± bir yol deÄŸil.  Bunun yerine uygulamalarÄ±mÄ±zda bunlarÄ± Ã§alÄ±ÅŸtÄ±rdÄ±klarÄ± sistemden okuyacaklarÄ± ÅŸekilde bir deÄŸiÅŸken olarak tanÄ±mlarÄ±z yani environment variable olarak tanÄ±mlarÄ±z.

Ã–rneÄŸin yukarÄ±daki veritabanÄ± senaryosunu baz alacak olursak. Bu veritabanÄ± bilgilerini deÄŸiÅŸkenlerin deÄŸerlerine bakacak ÅŸekilde ayarlarÄ±z.

Ne zaman bu imajdan bir container oluÅŸturmak istersek o an hangi deÄŸerler atanmasÄ± gerekiyorsa bu deÄŸerleri containerda environment variable olarak tanÄ±mlarÄ±z.

Environment variables containers: altÄ±nda env: anahtarÄ±yla tanÄ±mlanÄ±r.  Env altÄ±nda list ÅŸeklinde tÃ¼m environmentlar tanÄ±mlanÄ±r.
![]({{ 'assets/img/env.PNG' | relative_url }})


KÄ±saca resource limits ve environment variable konularÄ±na deÄŸinmeye Ã§alÄ±ÅŸtÄ±m UmarÄ±m faydalÄ± olmuÅŸtur. ğŸ˜Š

Bir sonraki yazÄ±mda gÃ¶rÃ¼ÅŸmek Ã¼zere ğŸ‘‹
